# 추가해야할 것들
## 알고리즘 대분류
### 지도학습(회귀, 분류)
선형회귀 및 분류, 의사결정나무, 앙상블, 나이브베이즈 분류, KNN, SVM, 인공신경망

### 분석 시 스케일링이 필요한 모델인지 확인하고 적용
+ 트리기반 모델은 스케일링이 불필요

### 비지도학습

## 1.회귀분석
+ gridsearchcv 사용했을 때 train 은 좋아지는데 test 가 좋아지지 않는 경우 어떻게 설명해야하는지?

+ 문제도 풀어보자

## 2. 의사결정나무
+ 분류에서 결과가 나왔을 때 결과 해석을 어떤식으로 해야할 지?

## 3. 앙상블
+ 회귀, 분류 예제에서 변수선택법으로 변수 선택하고 회귀, 분류 실행하는 과정 연습 필요

+ 부스팅에서 adaboostreg 로 했지만 xgboost, catboost 도 똑같음

+ 회귀
1. 훈련, 테스트 셋 분리
2. 모델 정하고 기본으로 돌려서 평가지표 출력(R2, mse)
3. 그리드서치로 최적의 파라미터 찾기
4. 찾은 파라미터로 2번 반복
5. 변수중요도 시각화

+ 분류
1. 훈련, 테스트 셋 분리
2. 모델 정하고 기본으로 돌려서 평가지표 출력(confusion_matrix, f1, recall, precision, roc_auc_score, classification_report)
3. 그리드서치로 최적의 파라미터 찾기
4. 찾은 파라미터로 2번 반복
5. 변수중요도 시각화

+ 스태킹 교재보고 추가하기

## 4. 나이브베이즈 분류
+ 가우시안 나이브베이즈 분류는 변수중요도 함수가 없음

+ 베르누이 나이브베이즈 분류에서 변수 중요도 함수? model.feature_log_prob_ 가 맞는지?

+ 다중 나이브베이즈 분류를 위한 종속변수가 범주형 변수인 데이터 찾기

## 5. KNN
+ 최적의 K를 찾을 때 반복문 vs GridsearchCV
+ 스케일링 해줘야 함

## 6. SVM
+ 스케일링이 필수
+ 그리드서치할 때 gamma, C 의 적정 값이 클 수 있음

## 7. 인공신경망
+ 스케일링 안한 것이 R2 값이 더 낮게 나오는데 그 이유는??

## 8. 클래스 불균형 처리
+ 언더샘플링, 오버샘플링, 샘플링X 3가지 비교해서 성능 좋은거로 학습


### 이상탐지 모델 추가해야