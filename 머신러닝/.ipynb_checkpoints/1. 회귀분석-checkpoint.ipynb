{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 회귀분석 개념\n",
    "+ 하나 혹은 그 이상의 원인이 종속변수에 미치는 영향을 추적하여 식으로 표현하는 통계기법\n",
    "+ 변수들 사이의 인과관계를 밝히고 모형을 적합하여 관심있는 변수를 예측하거나 추론하기 위해 사용하는 분석 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 머신러닝 기법을 이용한 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LinearRegression 은 계수 $ w = (w_1, ..., w_p)$ 를 사용하여 선형 모델을 피팅합니다.\n",
    "- 선형 모델은 X_train 으로 선형 근사에 의해 예측된 선형 회귀식과 y_train 사이의 잔여 제곱합을 최소화합니다.\n",
    "> LinearRegression() : 선형회귀분석 모델을 생성하는 함수  \n",
    "> fit() : 선형 회귀 모델에 필요한 두 가지 변수(x,y) 를 전달\n",
    "+ 설명변수의 차원을 조정해야 함\n",
    "+ R의 summary() 와 같은 기능이 없음\n",
    "+ 기울기와 절편을 따로 호출해서 얻을 수 있음\n",
    "+ 잔차를 자동으로 계산해주는 기능이 없음\n",
    "+ model.coef_ 로 회귀계수 추출가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Ridge, Lasso, ElasticNet\n",
    "+ Ridge\n",
    "> Ridge 회귀는 L2 정규화로 계수 크기에 페널티를 부과하여 일반 최소 제곱의 일부 문제를 해결합니다.  \n",
    "> 매개변수 : alpha = 1.0\n",
    "\n",
    "+ Lasso\n",
    "> Lasso 회귀는 L1 정규화로 희소 계수를 추정하는 선형 모델입니다.  \n",
    "> 매개변수 : alpha = 1.0\n",
    "\n",
    "+ ElasticNet\n",
    "> ElasticNet 회귀는 계수의 L1 및 L2 정규화로 훈련된 선형 회귀 모델입니다.  \n",
    "> 매개변수 : alpha = 1.0, l1_ratio = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 LinearRegression(예제)\n",
    "[예제]  \n",
    "boston 데이터로 LinearRegression을 사용하여 선형 회귀분석을 실시한 후, 추정된 회귀모형에 대해 해석하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mglearn\n",
    "X, y = mglearn.datasets.load_extended_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 테스트 셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('기울기', lr.coef_)\n",
    "print('절편', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2 score : 0.9469794920108199\n",
      "test r2 score : 0.6610321968877275\n",
      "mse : 25.25754030773469\n",
      "rmse : 5.025688043217037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('train r2 score :', lr.score(X_train, y_train))\n",
    "print('test r2 score :', lr.score(X_test, y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('mse :', mse)\n",
    "print('rmse :', np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[결과 해석]\n",
    "+ R2 값을 보면 훈련데이터에 비해 테스트데이터가 더 작으므로 과대적합이 일어났음을 알 수 있다.\n",
    "+ 선형회귀모델의 설명력은 약 66% 이다.\n",
    "+ 과대적합을 조정해주어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ridge, Lasso, ElasticNet\n",
    "+ Ridge, Lasso, ElasticNet 은 모두 alpha 값에 영향을 받는다.\n",
    "+ alpha 값을 통해 과대 적합을 피할 수 있다.\n",
    "+ alpha 값이 너무 크면 과소적합이 될 수 있으므로 최적의 값을 찾아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 GridSearchCV\n",
    "+ 모델에 지정된 매개변수 값에 대해 주어진 목록을 탐색해주는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Ridge(예제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mglearn\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "X,y = mglearn.datasets.load_extended_boston()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r2 score : 0.8636034860891285\n",
      "test r2 score : 0.8334633607570349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=1) # alpha = 1 기본값\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print('train r2 score :', ridge.score(X_train, y_train))\n",
    "print('test r2 score :', ridge.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[결과 해석]\n",
    "+ alpha = 1 일 때 R2 = 0.83 임을 알 수 있다.\n",
    "+ LinearRegression 모델의 R2보다는 좋지만 Ridge의 최적화된 값인지는 알 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 : {'alpha': 0.05}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge = Ridge()\n",
    "param_grid = {'alpha' : (0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.5, 1.0, 2.0 ,3.0)}\n",
    "grid_ridge = GridSearchCV(ridge, param_grid)\n",
    "grid_ridge.fit(X_train, y_train)\n",
    "\n",
    "print('최적의 파라미터 :', grid_ridge.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of using columns : 104\n",
      "train R2 : 0.9236984821715977\n",
      "test R2 : 0.8187788862166875\n",
      "mse : 13.50334617025127\n",
      "rmse : 3.674689942056509\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 0.05)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "print('number of using columns :', np.sum(ridge.coef_ != 0))\n",
    "print('train R2 :', ridge.score(X_train, y_train))\n",
    "print('test R2 :', ridge.score(X_test, y_test))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('mse :', mse)\n",
    "print('rmse :', np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Lasso(예제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 : {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "param_grid = {'alpha' : (0.001, 0.002, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2, 3)}\n",
    "grid_lasso = GridSearchCV(lasso, param_grid)\n",
    "grid_lasso.fit(X_train, y_train)\n",
    "\n",
    "print('최적의 파라미터 :', grid_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of using columns : 73\n",
      "train R2 : 0.9301687092322912\n",
      "test R2 : 0.7952457710491011\n",
      "mse : 15.256871429743258\n",
      "rmse : 3.906004535294763\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.001)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "print('number of using columns :', np.sum(lasso.coef_ != 0))\n",
    "print('train R2 :', lasso.score(X_train, y_train))\n",
    "print('test R2 :', lasso.score(X_test, y_test))\n",
    "\n",
    "y_pred = lasso.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('mse :', mse)\n",
    "print('rmse :', np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 ElasticNet(예제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0005, 'l1_ratio': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic = ElasticNet()\n",
    "param_grid = {'alpha' : (0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2, 3),\n",
    "              'l1_ratio' : np.arange(0.1, 1.0, 0.1)}\n",
    "\n",
    "grid_elastic = GridSearchCV(elastic, param_grid)\n",
    "grid_elastic.fit(X_train, y_train)\n",
    "\n",
    "print(grid_elastic.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of using columns : 99\n",
      "train r2 score : 0.916683017536598\n",
      "test r2 score : 0.8364575137697421\n",
      "mse : 12.186056905881786\n",
      "rmse : 3.4908533205910826\n"
     ]
    }
   ],
   "source": [
    "elastic = ElasticNet(alpha=0.0005, l1_ratio=0.5)\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "print('number of using columns :', np.sum(elastic.coef_ != 0))\n",
    "print('train r2 score :', elastic.score(X_train, y_train))\n",
    "print('test r2 score :', elastic.score(X_test, y_test))\n",
    "\n",
    "y_pred = elastic.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('mse :', mse)\n",
    "print('rmse :', np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.86021769,  -4.76995562,   0.15929522,   3.59055309,\n",
       "        12.88448725,  22.16519918,   7.16387974, -12.67298985,\n",
       "        14.67868258,  -2.01851942,  -0.92635441,  14.28495571,\n",
       "        -5.50029563,   5.82493522,   0.        ,  -2.11769176,\n",
       "        10.14633487,  -0.87533453,   4.73983577,  -3.24379985,\n",
       "        -0.        ,  -6.03576153,  -4.75544364,  -4.29349451,\n",
       "         2.61080454,  -1.56850798,   2.31963035,  -0.        ,\n",
       "         5.46753697,   0.37724755,   4.81568254,  -2.27123345,\n",
       "        -1.44995007,  -2.17615478,   7.3691262 ,   3.92219048,\n",
       "        -1.18983908,  -5.7470498 ,   5.02280786,   2.81234426,\n",
       "         7.65074545,   4.13230414,   7.76717303,  -3.82538926,\n",
       "        -5.29778791,   0.93665366, -11.25065109,  -1.19051905,\n",
       "       -15.62741401,   1.95150196, -16.07280729, -20.09124333,\n",
       "         2.24883322,  -8.23297116,   5.91804979,   7.51279894,\n",
       "        -4.06516495,  11.21243271,  -7.82027438,  -6.72337333,\n",
       "        -5.76004918,  -5.11988084,   0.        ,  -3.13206188,\n",
       "        -1.95233555,  -5.08544484,  -5.28179788,   3.06808424,\n",
       "        23.89439483,  -7.20263507,   6.1438811 , -20.30296868,\n",
       "       -18.00011065, -13.72608789,   7.32503192,  -3.93473739,\n",
       "        -1.10709897,   2.44222103,   8.09872797,  -2.40729788,\n",
       "        -1.59339881,  -6.76078547, -10.9399846 ,   9.22698203,\n",
       "        -2.76783455,  -7.32294974,  -0.        ,  -6.94406954,\n",
       "         4.94884713, -10.27794534,   4.95544229,  12.39562342,\n",
       "         1.13654004, -16.13995345,   5.21051258,  16.18278715,\n",
       "        -1.80692128, -15.4829782 ,   4.83533738,  -4.28993612,\n",
       "         3.8889    ,   0.9091259 ,  -4.73372788,  27.75841288])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 회귀 계수를 해석해야 할 경우, 0인 값을 제이하고 위와 같이 패널티가 적용된 회귀 계수를 가지고 해석하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge r2 : 0.8187788862166875\n",
      "lasso r2 : 0.7952457710491011\n",
      "ElasticNet r2 : 0.8364575137697421\n",
      "Linearregression r2 : 0.6610321968877275\n"
     ]
    }
   ],
   "source": [
    "# 회귀 모델 별 성능 비교\n",
    "print('ridge r2 :', ridge.score(X_test, y_test))\n",
    "print('lasso r2 :', lasso.score(X_test, y_test))\n",
    "print('ElasticNet r2 :', elastic.score(X_test, y_test))\n",
    "print('Linearregression r2 :', lr.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
